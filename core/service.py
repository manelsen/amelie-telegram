import re
import logging
import asyncio
from typing import Dict, Any, Optional
from datetime import datetime, timezone
from ports.interfaces import AIModelPort, SecurityPort, PersistencePort
from core.exceptions import VisionBotError, transientAPIError, PermanentAPIError, NoContextError

# ConfiguraÃ§Ã£o de logging profissional global para a AmÃ©lie
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
# Silenciamento de logs de infraestrutura para evitar poluiÃ§Ã£o visual
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("google_genai").setLevel(logging.WARNING)
logging.getLogger("telegram").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)

logger = logging.getLogger("VisionService")

class VisionService:
    """
    CÃ©rebro central da aplicaÃ§Ã£o AmÃ©lie (Core Domain Service).
    
    Orquestra o processamento multimodal, gerencia filas de mensagens, 
    garante a acessibilidade via limpeza de texto, controla timeouts de sessÃ£o 
    e aplica a blindagem criptogrÃ¡fica AES-256.
    """

    def __init__(self, ai_model: AIModelPort, security: SecurityPort, persistence: PersistencePort):
        """
        Inicializa o serviÃ§o core com os adaptadores necessÃ¡rios.

        Args:
            ai_model (AIModelPort): Adaptador para comunicaÃ§Ã£o com a IA.
            security (SecurityPort): Adaptador de criptografia e proteÃ§Ã£o de dados.
            persistence (PersistencePort): Adaptador de armazenamento persistente.
        """
        self.ai_model = ai_model
        self.security = security
        self.persistence = persistence
        self.queue = asyncio.Queue()
        self.worker_task = None
        # Tempo limite de inatividade (180 segundos)
        self.SESSION_TIMEOUT_SECONDS = 180

    def start_worker(self):
        """
        Inicia o Worker de processamento serializado no loop de eventos.
        
        Utiliza o padrÃ£o Lazy Initialization para garantir que o loop 
        esteja rodando no momento da criaÃ§Ã£o da task.
        """
        if self.worker_task is None:
            logger.info("Worker blindado da AmÃ©lie iniciado com sucesso.")
            self.worker_task = asyncio.create_task(self._worker())

    async def _worker(self):
        """
        Worker em background que processa a fila global.
        
        Garante a serializaÃ§Ã£o dos pedidos para evitar estouro de cota nas APIs
        e coordena o tempo de resposta do sistema.
        """
        while True:
            request = await self.queue.get()
            chat_id, func, args, future = request
            try:
                result = await func(*args)
                future.set_result(result)
            except Exception as e:
                future.set_exception(e)
            finally:
                self.queue.task_done()
                # Pausa estratÃ©gica para respeitar limites de cota
                await asyncio.sleep(0.5)

    def _clean_text_for_accessibility(self, text: str) -> str:
        """
        Sanitiza o texto removendo caracteres especiais de Markdown.

        Args:
            text (str): Texto bruto gerado pela IA.

        Returns:
            str: Texto limpo, amigÃ¡vel para softwares leitores de tela.
        """
        text = text.replace("*", "").replace("#", "").replace("_", " ").replace("`", "")
        text = re.sub(r' +', ' ', text)
        return text.strip()

    async def _enqueue_request(self, chat_id: str, func, *args):
        """
        Adiciona uma requisiÃ§Ã£o Ã  fila global e aguarda a conclusÃ£o.

        Args:
            chat_id (str): ID do chat solicitante.
            func: FunÃ§Ã£o do adaptador a ser executada.
            *args: Argumentos da funÃ§Ã£o.

        Returns:
            Any: O resultado da funÃ§Ã£o executada pelo worker.
        """
        loop = asyncio.get_running_loop()
        future = loop.create_future()
        await self.queue.put((chat_id, func, args, future))
        return await future

    async def process_file_request(self, chat_id: str, content_bytes: bytes, mime_type: str) -> str:
        """
        Coordena o processamento inicial de um novo arquivo.

        Realiza o upload, criptografia da URI e geraÃ§Ã£o da primeira audiodescriÃ§Ã£o.

        Args:
            chat_id (str): Identificador do usuÃ¡rio.
            content_bytes (bytes): ConteÃºdo binÃ¡rio do arquivo.
            mime_type (str): Tipo MIME do arquivo.

        Returns:
            str: Resposta inicial da AmÃ©lie sobre o arquivo.
        """
        logger.info(f"Recebido. Tipo: {mime_type} | Chat: {chat_id}")
        
        if not await self.persistence.has_accepted_terms(chat_id):
            return "POR_FAVOR_ACEITE_TERMOS"

        # Limpa cache do Google de sessÃµes anteriores do mesmo usuÃ¡rio
        session_data = await self.persistence.get_session(chat_id)
        if session_data:
            session, _ = session_data
            old_uri = self.security.decrypt(session["uri"])
            asyncio.create_task(self.ai_model.delete_file(old_uri))

        # Upload e blindagem via fila serializada
        file_uri = await self._enqueue_request(chat_id, self.ai_model.upload_file, content_bytes, mime_type)
        encrypted_uri = self.security.encrypt(file_uri)
        
        new_session = {
            "uri": encrypted_uri,
            "mime": mime_type,
            "history": []
        }
        await self.persistence.save_session(chat_id, new_session)
        
        # SeleÃ§Ã£o de prompt baseado em preferÃªncias persistentes
        style = await self.persistence.get_preference(chat_id, "style") or "longo"
        if mime_type.startswith("image/"):
            prompt = "Descreva esta imagem de forma muito breve (200 letras)." if style == "curto" else "Descreva detalhadamente esta imagem para um cego."
        elif mime_type.startswith("video/"):
            video_mode = await self.persistence.get_preference(chat_id, "video_mode") or "completo"
            if video_mode == "legenda":
                prompt = "Transcreva a faixa de Ã¡udio deste vÃ­deo palavra por palavra (verbatim), criando uma legenda fiel ao que Ã© dito."
            else:
                prompt = "Descreva este vÃ­deo detalhadamente de forma cronolÃ³gica para um cego."
        elif mime_type.startswith("audio/"):
            prompt = "Transcreva este Ã¡udio palavra por palavra (verbatim). NÃ£o inclua descriÃ§Ãµes ambientais, ruÃ­dos de fundo ou interpretaÃ§Ãµes de contexto. Apenas o texto do que Ã© dito."
        elif mime_type == "application/pdf":
            prompt = "Resuma este PDF de forma simples para um cego."
        elif mime_type == "text/csv":
            prompt = "Analise esta tabela CSV e descreva seus dados de forma clara para um cego."
        elif mime_type == "text/html" or mime_type == "text/xml":
            prompt = "Analise o conteÃºdo deste documento estruturado e extraia as informaÃ§Ãµes principais."
        else:
            prompt = "Analise este documento e descreva seu conteÃºdo para uma pessoa cega."

        result = await self.process_question_request(chat_id, prompt)
        logger.info(f"Processado. Tipo: {mime_type}")
        return result

    async def process_question_request(self, chat_id: str, question: str) -> str:
        """
        Processa perguntas de acompanhamento sobre o arquivo em cache.

        Args:
            chat_id (str): Identificador do usuÃ¡rio.
            question (str): Texto da pergunta.

        Returns:
            str: Resposta da IA sobre o contexto.

        Raises:
            NoContextError: Se nÃ£o houver arquivo ativo ou se a sessÃ£o expirou.
        """
        if not await self.persistence.has_accepted_terms(chat_id):
            return "POR_FAVOR_ACEITE_TERMOS"

        session_data = await self.persistence.get_session(chat_id)
        if not session_data:
            raise NoContextError("Sem contexto ativo.")
        
        session, updated_at_str = session_data
        
        # ValidaÃ§Ã£o de Inatividade (3 minutos)
        updated_at = datetime.strptime(updated_at_str, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
        diff = (datetime.now(timezone.utc) - updated_at).total_seconds()
        
        if diff > self.SESSION_TIMEOUT_SECONDS:
            logger.info(f"SessÃ£o expirada para {chat_id}. Limpando silenciosamente.")
            real_uri = self.security.decrypt(session["uri"])
            asyncio.create_task(self.ai_model.delete_file(real_uri))
            await self.persistence.clear_session(chat_id)
            raise NoContextError("SessÃ£o expirada.")

        # Desblindagem de dados para uso na IA
        real_uri = self.security.decrypt(session["uri"])
        real_history = []
        for h in session.get("history", []):
            real_history.append({
                "role": h["role"],
                "parts": [self.security.decrypt(p) for p in h["parts"]]
            })

        logger.info(f"Pergunta sobre cache: '{question[:30]}...' | Chat: {chat_id}")
        
        raw_result = await self._enqueue_request(
            chat_id, self.ai_model.ask_about_file, real_uri, session["mime"], question, real_history
        )

        clean_result = self._clean_text_for_accessibility(raw_result)
        
        # Re-blindagem e salvamento de histÃ³rico
        session["history"].append({"role": "user", "parts": [self.security.encrypt(question)]})
        session["history"].append({"role": "model", "parts": [self.security.encrypt(clean_result)]})
        
        await self.persistence.save_session(chat_id, session)
        return clean_result

    async def process_command(self, chat_id: str, command: str) -> str:
        """
        Gerencia comandos do usuÃ¡rio e persistÃªncia de preferÃªncias de interface.

        Args:
            chat_id (str): ID do usuÃ¡rio.
            command (str): Comando recebido (ex: '/curto').

        Returns:
            str: Mensagem explicativa de feedback para o usuÃ¡rio.
        """
        if command == "/start":
            if await self.persistence.has_accepted_terms(chat_id):
                return "OlÃ¡! Sou a AmÃ©lie. JÃ¡ nos conhecemos. Como posso ajudar hoje?"
            return "LGPD_NOTICE"

        if command == "/ajuda":
            return (
                "OlÃ¡! Sou a AmÃ©lie, sua assistente de audiodescriÃ§Ã£o e acessibilidade. ğŸ‘ï¸ğŸŒ¸\n\n"
                "Aqui estÃ¡ como vocÃª pode me usar:\n\n"
                "1. Envie uma mÃ­dia: Mande uma foto, vÃ­deo, Ã¡udio ou documento (PDF/MD).\n"
                "2. Pergunte detalhes: ApÃ³s enviar, vocÃª pode digitar perguntas sobre o arquivo.\n\n"
                "Comandos de ConfiguraÃ§Ã£o:\n"
                "/curto - Imagem: AudiodescriÃ§Ã£o breve (atÃ© 200 letras).\n"
                "/longo - Imagem: AudiodescriÃ§Ã£o detalhada (padrÃ£o).\n"
                "/legenda - VÃ­deo: TranscriÃ§Ã£o literal (verbatim) da fala presente no vÃ­deo.\n"
                "/completo - VÃ­deo: DescriÃ§Ã£o visual narrativa detalhada (padrÃ£o).\n"
                "/ajuda - Mostra esta mensagem de ajuda."
            )
        
        prefs = {"/curto": ("style", "curto"), "/longo": ("style", "longo"), 
                 "/legenda": ("video_mode", "legenda"), "/completo": ("video_mode", "completo")}
        
        if command in prefs:
            key, val = prefs[command]
            await self.persistence.save_preference(chat_id, key, val)
            
            if command == "/curto":
                return "O modo curto foi ativado com sucesso. Isso significa que as audiodescriÃ§Ãµes de imagem serÃ£o breves, com atÃ© 200 letras, ideais para uma identificaÃ§Ã£o rÃ¡pida."
            elif command == "/longo":
                return "O modo longo foi ativado com sucesso. Agora as audiodescriÃ§Ãµes de imagem serÃ£o completas e detalhadas, fornecendo o mÃ¡ximo de contexto visual."
            elif command == "/legenda":
                return "O modo legenda foi ativado com sucesso. A AmÃ©lie agora irÃ¡ transcrever a faixa de Ã¡udio dos vÃ­deos palavra por palavra (verbatim), gerando uma legenda fiel ao que Ã© dito."
            elif command == "/completo":
                return "O modo completo para vÃ­deos foi ativado com sucesso. As descriÃ§Ãµes de vÃ­deo agora serÃ£o narrativas e detalhadas."
            
            return f"PreferÃªncia atualizada: o modo {val} foi ativado!"
        
        return "Comando desconhecido. Digite /ajuda para ver as opÃ§Ãµes."

    async def accept_terms(self, chat_id: str):
        """
        Registra o consentimento definitivo do usuÃ¡rio no banco de dados.

        Args:
            chat_id (str): ID do usuÃ¡rio.
        """
        await self.persistence.accept_terms(chat_id)

    def get_lgpd_text(self) -> str:
        """
        Retorna o manifesto de privacidade e proteÃ§Ã£o de dados da AmÃ©lie.

        Returns:
            str: Texto do manifesto de consentimento.
        """
        return (
            "OlÃ¡, eu sou a AmÃ©lie! ğŸ‘ï¸ğŸŒ¸\n\n"
            "Antes de comeÃ§armos, preciso informar como cuido da sua privacidade em conformidade com a LGPD:\n\n"
            "1. Blindagem Total: Suas imagens, vÃ­deos e conversas sÃ£o protegidos por criptografia de ponta AES-256 antes mesmo de serem salvos. Nem meus gestores conseguem ler o seu histÃ³rico.\n"
            "2. Processamento Seguro: Seus arquivos sÃ£o enviados temporariamente para o Google Gemini apenas para anÃ¡lise e deletados automaticamente apÃ³s o uso.\n"
            "3. Seus Direitos: Seus dados pertencem a vocÃª. Usamos a tecnologia para ampliar sua visÃ£o, nÃ£o para vigiÃ¡-lo.\n\n"
            "Ao clicar no botÃ£o abaixo, vocÃª concorda com estes termos e podemos iniciar nossa jornada juntos."
        )
